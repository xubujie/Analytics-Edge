boston = read.csv("boston.csv")
plot(boston$LON, boston$LAT)
setwd("~")
setwd("Desktop/Analytics Edge/Unit 4 Tree/data/")
boston = read.csv("boston.csv")
plot(boston$LON, boston$LAT)
str(boston)
library(caTools)
split = sample.split(boston, SplitRatio = 0.7)
split = sample.split(boston$MEDV, SplitRatio = 0.7)
train = subset(boston, split == TRUE)
test = subset(boston, split == FALSE)
linear.reg = lm(MEDV ~ LON + LAT + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +
TAX + PTRATIO, data = train)
summary(linear.reg)
cor(train)
predict.linear = predict(linear.reg, newdata = test)
sse = sum((predict.linear - test$MEDV)^2)
sse
library(rpart)
library(rpart.plot)
tree = rpart(MEDV ~ LON + LAT + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +
TAX + PTRATIO, data = train)
prp(tree)
predict.tree = predict(tree, newdata = test)
SSE = sum((predict.linear - test$MEDV)^2)
SSE.linear = sum((predict.linear - test$MEDV)^2)
SSE.tree = sum((predict.tree - test$MEDV)^2)
SSE.tree
library(e1071)
library(caret)
num.flods = trainControl(method="cv", number=10)
cp.grid = expand.grid(.cp=seq(0,0.1,0.001))
num.flods = trainControl(method="cv", number=10)
cp.grid = expand.grid(.cp=seq(0,0.1,0.001))
tr.cross = train(MEDV ~ LON + LAT + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +
TAX + PTRATIO, method="rpart", trControl=num.flods, tune.grid=cp.grid)
tr.cross = train(MEDV ~ LON + LAT + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +
TAX + PTRATIO, data=train,method="rpart",
trControl=num.flods, tune.grid=cp.grid)
tr.cross
cp.grid = expand.grid(.cp=seq(0,0.1,0.001))
cp.grid = expand.grid(.cp=seq(0,1,0.01))
tr.cross = train(MEDV ~ LON + LAT + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +
TAX + PTRATIO, data=train,method="rpart",
trControl=num.flods, tune.grid=cp.grid)
num.flods = trainControl(method="cv", number=10)
cp.grid = expand.grid(.cp=seq(0,0.11,0.001))
tr.cross = train(MEDV ~ LON + LAT + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +
TAX + PTRATIO, data=train,method="rpart",
trControl=num.flods, tuneGrid=cp.grid)
tr.cross
best.tree = tr.cross$finalModel
prp(best.tree)
predict.best.tree = predict(best.tree, newdata = test)
SSE.best.tree = sum((predict.best.tree-test$MEDV)^2)
SSE.best.tree
summary(best.tree)
library(randomForest)
library(randomForest)
randomForest = randomForest(MEDV ~ LON + LAT + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +
TAX + PTRATIO, data = train)
randomForest = randomForest(MEDV ~ LON + LAT + CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD +
TAX + PTRATIO, data = train, nodsize=20, ntree=200)
predict.randomForest = predict(randomForest, newdata = test)
SSE.randomForest = sum((predict.randomForest - test$MEDV)^2)
SSE.linear
SSE.tree
SSE.randomForest
SSE.best.tree
predict.randomForest
plot(predict.randomForest, test$MEDV)
getwd()
gerber = read.csv("gerber.csv")
str(gerber)
mean(gerber$voting)
mean(gerber$voting[gerber$civicduty == 1])
mean(gerber$voting[gerber$civicduty == 1])
mean(gerber$voting[gerber$hawthorne == 1])
mean(gerber$voting[gerber$neighbors == 1])
mean(gerber$voting[gerber$self == 1])
vote.log = glm(voting ~ hawthorne + civicduty + neighbors + self, data = gerber, family = binomial)
summary(vote.log)
log.pred = predict(vote.log)
table(gerber$voting, log.pred > 0.3)
log.pred = predict(vote.log, type = "response")
table(gerber$voting, log.pred > 0.3)
(134513+51966)/(134513+51966+100875+56730)
table(gerber$voting, log.pred > 0.3)
table(gerber$voting, log.pred > 0.5)
log.pred = predict(vote.log, type = "response")
table(gerber$voting, log.pred > 0.5)
table(gerber$voting, log.pred > 0.3)
table(gerber$voting, log.pred > 0.5)
235388/(235388+108696)
library(ROCR)
predROCR = prediction(log.pred, gerber$voting)
auc = as.numeric(performance(predROCR, "auc")@y.values)
auc
library(rpart)
library(rpart.plot)
cart.model = rpart(voting ~ civicduty + hawthorne + neighbors + self, data = gerber)
prp(cart.model)
summary(cart.model)
cart.model2 = rpart(voting ~ civicduty + hawthorne + neighbors + self, data = gerber,
cp = 0.0)
prp(cart.model2)
?rpart
cart.model = rpart(voting ~ civicduty + hawthorne + neighbors + self, data = gerber, cp = 1)
prp(cart.model)
cart.model = rpart(voting ~ civicduty + hawthorne + neighbors + self, data = gerber)
prp(cart.model)
cart.model2 = rpart(voting ~ civicduty + hawthorne + neighbors + self, data = gerber,
cp = 0.0)
prp(cart.model2)
str(gerber)
cart.model3 = rpart(voting ~ civicduty + hawthorne + neighbors + self + sex, data = gerber,
cp = 0.0)
prp(cart.model3)
control.cart.model = rpart(voting ~ control, data=gender, cp=0.0)
control.cart.model = rpart(voting ~ control, data=gerber, cp=0.0)
control.cart.model2 = rpart(voting ~ control, data=gerber, cp=0.0)
prp(control.cart.model, digits = 6)
0.34-0.296638
prp(control.cart.model2, digits = 6)
control.cart.model2 = rpart(voting ~ control + sex, data=gerber, cp=0.0)
prp(control.cart.model2, digits = 6)
controlLog = glm(voting ~ control + sex, data = gerber, family = binomial)
summary(controlLog)
possibilities = data.frame(sex=c(0,0,1,1), control=c(0,1,0,1))
predict(controlLog, newdata = possibilities, type = "response")
0.290456 - 0.2908065
controlLog2 = glm(voting ~ control + sex + sex:control, data = gerber, family = "binomial")
summary(controlLog2)
predict(controlLog2, newdata = possibilities, type = "response")
0.3341757 - 0.290456
letters = read.csv("letters_ABPR.csv")
letters$isB = as.factor(letters$letter == "B")
str(letters)
library(caTools)
split = sample.split(letters$isB, SplitRatio = 0.5)
train = subset(letters, split == TRUE)
test = subset(letters, split == FALSE)
table(test$isB)
(1175)/(1175+383)
library(rpart)
library(rpart.plot)
CARTb = rpart(isB ~ .-letter, data = train, method = "class")
predictB = predict(CARTb, newdata = test, type = "class")
table(test$isB, predictB)
(1132+339)/(1132+339+43+44)
library(caTools)
set.seed(1000)
split = sample.split(letters$isB, SplitRatio = 0.5)
train = subset(letters, split == TRUE)
test = subset(letters, split == FALSE)
table(test$isB)
# Tree
library(rpart)
library(rpart.plot)
CARTb = rpart(isB ~ .-letter, data = train, method = "class")
predictB = predict(CARTb, newdata = test, type = "class")
table(test$isB, predictB)
(1118+340)/(1118+340+57+43)
library(randomForest)
randomForestB = randomForest(isB ~ .-letter, data = train)
randomForest.predictB = predict(randomForestB, newdata = test, type = "class")
table(test$isB, predictB)
(1118+340)/(1118+340+57+43)
table(test$isB, randomForest.predictB)
(1164 + 373)/(1164+11+10+373)
letters$letter = as.factor(letters$letter)
set.seed(2000)
split = sample.split(letters$letter, SplitRatio = 0.5)
train = subset(letters, split == TRUE)
test = subset(letters, split == FALSE)
table(test$letter)
401/nrow(test)
CART = rpart(letter ~ . - isB, data = train, method = "class")
CART.pred = predict(CART, newdata = test, type = "class")
table(test$letter, CART.pred)
(348+318+363+340)/nrow(test)
RF = randomForest(letter ~ . - isB, data = train)
RF.pred = predict(RF, newdata = test, type = "class")
table(test$letter, RF.pred)
(390+380+393+369)/nrow(test)
census = read.csv("census.csv")
str(census)
library(caTools)
set.seed(2000)
split = sample.split(census$over50k, SplitRatio = 0.6)
train = subset(census, split == TRUE)
test = subset(census, split == FALSE)
log.model = glm(over50k ~ ., data = train, family = "binominol")
log.model = glm(over50k ~ ., data = train, family = binomial)
summary(log.model)
log.pred = predict(log.model, newdata = test, type = "response")
table(test$over50k, log.pred > 0.5)
(9051 + 1888)/nrow(test)
table(test$over50k)
9713/nrow(test)
library(ROCR)
predROCR = prediction(log.pred, test$over50k)
auc = as.numeric(performance(predROCR, "auc")@y.values)
auc
library(rpart)
library(rpart.plot)
cart = rpart(over50k ~ ., data = train, method = "class")
prp(cart)
cart.pred = predict(cart, newdata = test, type = "class")
table(test$over50k, cart.pred)
(9243+1596)/nrow(test)
log.ROCRperf = performance(predROCR, "tpr", "fpr")
plot(log.ROCRperf)
cart.pred = predict(cart, newdata = test)
cart.ROCRpred = prediction(cart.pred, test$over50k)
cart.ROCRpred = prediction(cart.pred, test$over50k)
cart = rpart(over50k ~ ., data = train)
prp(cart)
cart.pred = predict(cart, newdata = test)
table(test$over50k, cart.pred > 0.5)
cart.ROCRpred = prediction(cart.pred, test$over50k)
table(test$over50k, cart.pred > 0.5)
cart = rpart(over50k ~ ., data = train, method = "class")
prp(cart)
cart.pred = predict(cart, newdata = test)
table(test$over50k, cart.pred > 0.5)
cart.pred = predict(cart, newdata = test, type = "response")
cart.pred = predict(cart, newdata = test, type = "class")
table(test$over50k, cart.pred > 0.5)
table(test$over50k, cart.pred)
cart.pred = predict(cart, newdata = test)
table(test$over50k, cart.pred)
cart.pred = predict(cart, newdata = test)
table(test$over50k, cart.pred[,2]>0.5)
cart.ROCRpred = prediction(cart.pred[,2], test$over50k)
cart.ROCRperf = performance(cart.ROCRpred, "tpr", "fpr")
par(mfrow=c(2,1))
plot(log.ROCRperf)
plot(cart.ROCRperf)
prp(cart)
cart = rpart(over50k ~ ., data = train, method = "class",cp=0.01)
prp(cart)
cart = rpart(over50k ~ ., data = train, method = "class",cp=0.05)
prp(cart)
par(mfrow=c(1,1))
prp(cart)
cart.auc = as.numeric(performance(cart.ROCRpred, "auc")@y.values)
cart.auc
# randomForest
set.seed(1)
trainSmall = train[sample(nrow(train), 2000), ]
library(randomForest)
RF = randomForest(over50k ~ ., data = trainSmall)
RF.pred = predict(RF, newdata = test)
table(test$over50k, RF.pred > 0.5)
head(RF.pred)
table(test$over50k, RF.pred)
(9614+1050)/nrow(test)
str(train)
RF = randomForest(over50k ~ ., data = train)
RF.pred = predict(RF, newdata = test)
table(test$over50k, RF.pred)
(9690+864)/nrow(test)
trainSmall = train[sample(nrow(train), 2000), ]
RF = randomForest(over50k ~ ., data = trainSmall)
RF.pred = predict(RF, newdata = test)
table(test$over50k, RF.pred)
vu = varUsed(RF, count=TRUE)
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
vu
vusorted
dotchart(vusorted$x, names(RF$forest$xlevels[vusorted$ix]))
varImpPlot(MODEL)
varImpPlot(RF)
library(caret)
library(e1071)
num.folds = trainControl(method = "cv", number = 10)
cp.grid = expand.grid(.cp = seq(0.002, 0.1, 0.002))
CV = train(over50k ~ ., method = "rpart", trControl = num.folds, tuneGrid = cp.grid)
CV = train(over50k ~ ., method = "rpart", trControl = num.folds, tuneGrid = cp.grid,
data = train)
CV
cart = rpart(over50k ~ ., data = train, method = "class", cp = 0.002)
prp(cart)
cart.pred = predict(cart, newdata = test)
table(test$over50k, cart.pred[,2]>0.5)
(9178+1838)/nrow(test)
predROCR = prediction(log.pred, test$over50k)
auc = as.numeric(performance(predROCR, "auc")@y.values)
log.ROCRperf = performance(predROCR, "tpr", "fpr")
cart.ROCRpred = prediction(cart.pred[,2], test$over50k)
cart.ROCRperf = performance(cart.ROCRpred, "tpr", "fpr")
cart.auc = as.numeric(performance(cart.ROCRpred, "auc")@y.values)
par(mfrow=c(2,1))
plot(log.ROCRperf)
plot(cart.ROCRperf)
par(mfrow=c(1,1))
prp(cart)
